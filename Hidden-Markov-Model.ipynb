{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 隐马可夫模型 (Hidden Markov Model)\n",
    "\n",
    "隐马可夫模型（HMM）是一个针对序列的生成式模型（Generative Model）。常见的序列是书上的一个句子或者说出的一句话。比如在给出一串语音的时候，希望计算机可以推断出究竟说的是哪些词，这个场景就可以用隐马模型建模。\n",
    "\n",
    "语音识别首先面对的问题就是怎么处理发音的差异。比如，让不同的人读 “philosophy” 这个词，男女老少读出来的是不一样的语音序列。人们可以轻松的识别出 “philosopy” 就说明每个词在统计意义上是有其特征的。隐马模型就可以用来寻找这个特征，从而识别语音。\n",
    "\n",
    "隐马模型中区分观察到的状态和隐藏的状态。上面的例子中，不同人的发音就是观察到的状态，对应 “philosopy” 的特征就是隐藏状态。上面所谓的“生成式模型”可以理解成，每个认识 “philosophy” 的人都知道它的发音特征，基于这个认识调动喉部肌肉“产生出”发声。所以“生成式”强调“从隐藏状态产生观察状态”的过程。\n",
    "\n",
    "单词的发音显然是一个时序过程，单词的发音特征就可以用时序模型建模。马可夫过程是一个简单时序模型，强调给定当前状态就可以推断出下个状态的概率分布，历史状态不会提供额外的信息。在语义识别上这当然是个很不实际的假设，但是在声音的浅层识别（比如音频到音素识别）上还是有效的，所以单词的发音特征序列就可以用马可夫链来建模。\n",
    "\n",
    "下面看看模型的具体定义。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM 模型定义\n",
    "\n",
    "隐马模型的概率图是这个样子的（图来自 Hulu 机器学习第二十六讲）：\n",
    "\n",
    "<img src=\"hmm-graph.png\">\n",
    "\n",
    "隐藏状态序列（$x_i$）形成一个马可夫链，观察状态（$y_i$）依据每个节点上隐藏状态所对应的概率分布随机产生。\n",
    "\n",
    "准确定义这个模型需要下面三个参数：\n",
    "\n",
    "1. $p(x_1)$，初始隐藏状态的概率分布\n",
    "1. $p(x_{i+1} \\mid x_i)$，隐藏状态之间的转换概率\n",
    "1. $p(y_i \\mid x_i)$，从隐藏状态到观察状态的概率分布\n",
    "\n",
    "假设有 $K$ 种隐藏状态，有 $D$ 种观察状态，在离散的情况下，$p(x_1)$ 是 $K$ 个元素的数组；$p(x_{i+1} \\mid x_i)$ 是 $K \\times K$ 的矩阵；$p(y_i \\mid x_i)$ 是 $K \\times D$ 的矩阵。\n",
    "\n",
    "训练（学习）一个 HMM 模型既是寻找这三个参数的过程。比如可以为每个单词训练一个 HMM，各自有对应的参数。有了多个模型之后，针对给定的一个单词的读音，可以计算哪个模型产生这个读音的概率最大（即模型评估），从而识别单词。\n",
    "\n",
    "在分词的场景中，可以用一个训练好的模型去分解一个句子，寻找最可能的拆分方案。拆分方案就是隐藏状态，寻找最优方案的过程可以认为是寻找最优编码。\n",
    "\n",
    "应用 HMM 是主要面对的就是上面提到的三个问题：训练，模型评估，解码。下面用掷色子的例子介绍一下面对三个问题时使用的算法。语音识别和分词的问题以后会继续。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 掷色子\n",
    "\n",
    "这个例子取自 [Hidden Markov Models - the Unfair Casino](http://web.stanford.edu/class/stats366/hmmR2.html).\n",
    "\n",
    "这里有两个色子，一个是正常的（即六个面是等概率的），另一个做了手脚，使 6 出现的概率为 0.5，其余 5 个面出现的概率都是 0.1。如果每次随机选取一个色子，然后抛出它将得到一个数字，重复多次可以得到一个数字序列。\n",
    "\n",
    "假设对选择色子的随机过程做如下限制：\n",
    "1. 开始时的色子根据一个概率 $p(x_1)$ 分布选择\n",
    "1. 后续色子是根据一个马可夫链状态转换矩阵 $p(x_{i+1} \\mid x_i)$ 中的概率来选择\n",
    "\n",
    "，然后抛掷被选的色子得到数字序列，那整个过程将可以用 HMM 建模。\n",
    "\n",
    "\n",
    "下面看一下解码的问题，即在知道 $p(x_1), p(x_{i+1} \\mid x_i), p(y_i \\mid x_i)$ 的情况下，对给定的 $Y = (y_1, y_2, \\dots, y_n)$ 序列，如何求出最可能的 $X = (x_1, x_2, \\dots, x_n)$ 序列。具体到这个问题就是，看到了一串数字，想知道它们都是哪个色子掷出的。\n",
    "\n",
    "### 解码\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先定义 HMM 参数（完整的实现在 [HMM-import.ipynb](HMM-import.ipynb) 里）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run HMM-import.ipynb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] =[12,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择第一个色子时的概率\n",
    "pi = np.array([0.5, 0.5])\n",
    "# 两个色子的状态转换矩阵\n",
    "transp = np.array([[0.99, 0.01], [0.02, 0.98]])\n",
    "# 两个色子各自的投掷概率\n",
    "emissp = np.array([[1/6, 1/6, 1/6, 1/6, 1/6, 1/6], [0.1, 0.1, 0.1, 0.1, 0.1, 0.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面根据这些参数执行模拟过程，产生出观测数字序列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(N):\n",
    "    hs = []\n",
    "    xs = []\n",
    "    ht = np.random.choice([0,1], p=pi)\n",
    "    hs.append(ht)\n",
    "    for _ in range(N-1):\n",
    "        ht = np.random.choice([0, 1],p=transp[ht, :])\n",
    "        hs.append(ht)\n",
    "    for h in hs:\n",
    "        xt = np.random.choice(range(6), p=emissp[h, :])\n",
    "        xs.append(xt)\n",
    "    return hs, xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs, vs = simulate(800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hs 是隐藏状态序列，即每一步是哪个色子被投掷。vs 是观察到的数字序列。\n",
    "\n",
    "\n",
    "下面看如何根据观察序列推断出最可能的隐藏序列。这个问题用公式表达出来就是 $max_{X}\\log{p(X \\mid Y)}$。因为 $p(X \\mid Y) = \\frac{p(X, Y)}{p(Y)}$，而分母 $p(Y)$ 是跟 $X$ 无关的量，所以上面的最大化可以用 $max_{X}\\log{p(X, Y)}$ 代替。\n",
    "\n",
    "因为 $p(X, Y) = p(x_1)\\prod_{n=1}^{N}p(y_n \\mid x_n)\\prod_{m=2}^{N}p(x_m \\mid x_{m-1})$，最大化的表达式为：\n",
    "\n",
    "$$\n",
    "max_{X}\\log{p(x_1)} + \\sum_{n=1}^{N}{\\log{p(y_n \\mid x_n)}} + \\sum_{m=2}^{N}{\\log{p(x_m \\mid x_{m-1})}}.\n",
    "$$\n",
    "\n",
    "这个最大化本质是尝试所有 $X$ 的可能组合，找到值最大的一组。但由于变量之间有限的相关性（$x_m$ 只与 $x_{m-1}$ 相关），尝试所有组合将引发大量重复的计算。这个问题可以用 max-sum 算法解决。max-sum 算法是一个通用的，利用条件无关性（conditional-independence）来解决重复计算问题的算法框架。具体到 HMM 上就是称为 Viterbi 的算法（Andrew Viterbi 1967年提出）。max-sum 和 viterbi 都属于动态规划算法，背后的基础都是条件无关性，以后会专门说说动态规划。下面简单看一下如何得出 viterbi 算法。\n",
    "\n",
    "上面最大化表达式是关于 $(x_1, x_2, \\dots, x_N)$ 的函数，与 $Y$ 无关，展开后表示为：\n",
    "\n",
    "$$\n",
    "max_{X}\\log{p(x_1)} + \\log{p(y_1 \\mid x_1)} + \\log{p(x_2 \\mid x_{1})} + \\log{p(y_2 \\mid x_2)} + \\log{p(x_3 \\mid x_{2})} + \\log{p(y_3 \\mid x_3)} + \\cdots + \\log{p(x_N \\mid x_{N-1})} + \\log{p(y_N \\mid x_N)}.\n",
    "$$\n",
    "\n",
    "如果设：\n",
    "\\begin{align}\n",
    "f_1(x_1, x_2) & = \\log{p(x_1)} + \\log{p(y_1 \\mid x_1)} + \\log{p(x_2 \\mid x_{1})} + \\log{p(y_2 \\mid x_2)}\\\\\n",
    "f_2(x_2, x_3) & = \\log{p(x_3 \\mid x_{2})} + \\log{p(y_3 \\mid x_3)}\\\\\n",
    "f_{n-1}(x_{n-1}, x_n) & = \\log{p(x_n \\mid x_{n-1})} + \\log{p(y_n \\mid x_n)}\n",
    "\\end{align}\n",
    "，最大化表达式可以表示为：\n",
    "\n",
    "$$\n",
    "max_{x_1,x_2,\\dots,x_n} f_1(x_1,x_2) + f_2(x_2, x_3) + f_3(x_3, x_4) + \\dots + f_{n-1}(x_{n-1}, x_n).\n",
    "$$\n",
    "\n",
    "为了避免重复计算，首先注意到 $x_1$ 的变动只影响 $f_1$ 的值。如果定义：\n",
    "$$\n",
    "h_1(x_2) = max_{x_1}f_1(x_1,x_2)\n",
    "$$\n",
    "，就可以简化最大化表达式为：\n",
    "$$\n",
    "max_{x_2,\\dots,x_n} h_1(x_2) + f_2(x_2, x_3) + f_3(x_3, x_4) + \\dots + f_{n-1}(x_{n-1}, x_n).\n",
    "$$\n",
    "\n",
    "$h_1(x_2)$ 这个函数是 $x_2$ 到 $f_1(*, x_2)$ 极值的映射，$*$ 号代表尝试所有的 $x_1$。另外注意一下，最大化表达式的下标中已经去掉了 $x_1$。只所以能做这个简化就是因为 $x_1$ 的变动只影响 $f_1$ 的值，不影响其他 $f_i$ 的值。或者说 $x_1$ 对最大值的影响已经完全包含在了 $h_1$ 这个函数里。\n",
    "\n",
    "相应的，$x_2$ 的变动只影响到 $h_1$ 和 $f_2$，可以继续定义：\n",
    "$$\n",
    "h_2(x_3) = max_{x_2}h_1(x_2) + f_2(x_2, x_3)\n",
    "$$\n",
    "，最大化表达式进一步简化为：\n",
    "$$\n",
    "max_{x_3,\\dots,x_n} h_2(x_3) + f_3(x_3, x_4) + \\dots + f_{n-1}(x_{n-1}, x_n).\n",
    "$$\n",
    "\n",
    "这次减掉了 $x_2$。$h_i$ 函数的下标可以认为是减掉的第几个 $x$ 变量。\n",
    "\n",
    "这个过程继续下去，最后可以简化为：\n",
    "$$\n",
    "max_{x_n} h_{n-1}(x_n).\n",
    "$$\n",
    "其中\n",
    "$$\n",
    "h_{n-1}(x_n) = max_{x_{n-1}}h_{n-2}(x_{n-1}) + f_{n-1}(x_{n-1}, x_n).\n",
    "$$\n",
    "\n",
    "实际的计算过程就是逐次计算 $h_i$ 的过程，最后的极值由 $max_{x_n} h_{n-1}(x_n)$ 得出。\n",
    "\n",
    "那如何得知是哪一组 $X$ 取得了最大值呢？\n",
    "\n",
    "由最后一步可以知道是从哪个 $x_n$ 取得了最大值，记为 $x_n^{max} = argmax_{x_n} h_{n-1}(x_n)$。有了 $x_n^{max}$ 就可以回填到 $h_{n-1}$ 的表达式，找到 $x_{n-1}^{max}$：$x_{n-1}^{max} = argmax_{x_{n-1}}h_{n-2}(x_{n-1}) + f_{n-1}(x_{n-1}, x_n^{max})$。这个过程可以一直回溯到 $x_1^{max}$，这样就找到了最可能的一组 $X$。这个过程叫 back-tracing。\n",
    "\n",
    "下面是 HMM viterbi 算法的实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HMMViterbi(v):\n",
    "    N = len(v)\n",
    "    trace = np.zeros((N, 2))\n",
    "    trace[0, :] = np.log(pi) + np.log(emissp[:, v[0]])\n",
    "    traj = np.ones((N, 2)) * -1\n",
    "    for i in range(1, N):\n",
    "        s = np.log(transp.T) + np.log(emissp[:, v[i]]) + trace[i-1,:]\n",
    "        trace[i,:] = np.max(s.T, axis=0)\n",
    "        traj[i, :] = np.argmax(s.T, axis=0)\n",
    "    hs = []\n",
    "    last = np.argmax(trace[N-1,:])\n",
    "    hs.append(last)\n",
    "    for i in range(N-1, 0, -1):\n",
    "        last = int(traj[i, last])\n",
    "        hs.append(last)\n",
    "    return list(reversed(hs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面看一下效果。比较一下真实的色子状态和推测出的最可能色子状态。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 800 artists>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114e7e588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "phs = HMMViterbi(vs)\n",
    "\n",
    "#vs, hs, phs\n",
    "\n",
    "hscolor = ['green' if h == 0 else 'red' for h in hs]\n",
    "\n",
    "phscolor = ['green' if h == 0 else 'red' for h in phs]\n",
    "\n",
    "fig, ax = plt.subplots(3, 1)\n",
    "ax[0].bar(range(len(hs)), 1, color=hscolor)\n",
    "ax[1].bar(range(len(hs)), 1, color=phscolor)\n",
    "ax[2].bar(range(len(hs)), np.array(vs)+1,color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面第一行是真实的色子状态，第二行是推测出的最可能的色子状态，红色代表作了手脚的色子，绿色代表正常的色子。第三行是色子掷出的数字。\n",
    "\n",
    "可以看到推测出的隐藏状态接近真实的隐藏状态。\n",
    "\n",
    "### 训练参数\n",
    "\n",
    "上面展示了在知道 HMM 参数的情况下，从观察序列推测隐藏序列的过程。那 HMM 的参数如何训练呢？\n",
    "\n",
    "如果知道观察序列并且知道隐藏序列，HMM 的参数训练比较简单。通过简单的计数就可以得到隐藏状态的转换矩阵和从隐藏状态到观察状态的概率分布。如果只知道观察序列不知道隐藏序列，可以用期望最大化（Expectation-Maximization，EM）算法来训练。\n",
    "\n",
    "期望最大化算法通过循环交替下面两步来求解（假设所有的参数都包含在 $\\theta$ 里）：\n",
    "1. 在现有 $\\theta^{old}$ 的条件下，估计隐藏状态的概率分布\n",
    "1. 在现有隐藏状态的估计下，寻找最优的模型参数 $\\theta^{new}$。\n",
    "\n",
    "循环的过程会持续的改进模型产生观察序列的概率，即 $p(X \\mid \\theta)$。当改进停止或者改进幅度非常小的时候可以终止循环。要启动循环需要初始化模型参数，最好可以利用一些先验知识，没有的话就随机初始化参数 $\\theta^{init}$。由于 EM 算法很容易收敛于局部最优解，可以运行多次 EM 算法（得到多个不同的初始参数 $\\theta^{init}$），以增加得到全局最优解的机会。\n",
    "\n",
    "HMM 的 EM 算法推导过程会另写一篇，下面看一下效果。\n",
    "\n",
    "先定义辅助函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HMMforward(v, N, K, pi_, emissp_, transp_):\n",
    "    logalpha = np.ones((N, K)) * -np.inf\n",
    "    logalpha[0, :] = np.log(pi_) + np.log(emissp_[:, v[0]])\n",
    "    for i in range(1, N):\n",
    "        logalpha[i, :] = np.log(emissp_[:, v[i]]) + logsumexp(logalpha[i-1, :] + np.log(transp_.T), axis=1)\n",
    "    return logalpha, logsumexp(logalpha[N-1,:])\n",
    "\n",
    "def HMMbackward(v, N, K, emissp_, transp_):\n",
    "    logbeta = np.ones((N, K)) * -np.inf\n",
    "    logbeta[N-1, :] = np.zeros(K)\n",
    "    for i in range(N-2, -1, -1):\n",
    "        logbeta[i, :] = logsumexp(logbeta[i+1, :] + np.log(emissp_[:, v[i+1]]) + np.log(transp_), axis=1)\n",
    "    return logbeta\n",
    "\n",
    "def HMMsmooth(logalpha, logbeta, v, N, K, emissp_, transp_):\n",
    "    r = np.zeros((N, K))\n",
    "    for i in range(N):\n",
    "        r[i, :] = logalpha[i, :] + logbeta[i, :]\n",
    "    r = condexp(r)\n",
    "    A = np.zeros((K, K, N))\n",
    "    for i in range(1, N):\n",
    "        A[:, :, i] = np.matlib.repmat(logalpha[i-1, :].reshape(-1,1), 1, 2) + logbeta[i, :] + np.log(emissp_[:, v[i]]) + np.log(transp_[:, :])\n",
    "        logmax = np.max(A[:, :, i])\n",
    "        A[:, :, i] -= logmax\n",
    "        A[:, :, i] = np.exp(A[:, :, i])\n",
    "        A[:, :, i] = A[:, :, i] / np.sum(A[:, :, i])\n",
    "    return r, A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再定义 EM 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HMMem(V, N, K, D, niters):\n",
    "    ph1 = condp(np.random.rand(K)) # pi\n",
    "    phthtp = condp(np.random.rand(K, K)) # transp\n",
    "    pvtht = condp(np.random.rand(K, D)) # emissp\n",
    "    times = 0\n",
    "    lastllik = -np.inf\n",
    "    for i in range(niters):\n",
    "        a = np.zeros(K)\n",
    "        A = np.zeros((K, K))\n",
    "        B = np.zeros((K, D))\n",
    "        llik = 0\n",
    "        for m in range(len(V)):\n",
    "            v = V[m]\n",
    "            # E-step\n",
    "            logalpha, llik_ = HMMforward(v, N, K, ph1, pvtht, phthtp)\n",
    "            logbeta = HMMbackward(v, N, K, pvtht, phthtp)\n",
    "            r, A_ = HMMsmooth(logalpha, logbeta, v, N, K, pvtht, phthtp)\n",
    "            llik += llik_\n",
    "            # collect\n",
    "            a += r[0, :]\n",
    "            A += np.sum(A_, axis=2)\n",
    "            for j in range(N):\n",
    "                B[:, v[j]] += r[j, :]\n",
    "        # M-step\n",
    "        ph1 = condp(a)\n",
    "        phthtp = condp(A)\n",
    "        pvtht = condp(B)\n",
    "        llik /= len(V)\n",
    "        if llik - lastllik < 0.003:\n",
    "            times += 1\n",
    "        else:\n",
    "            times = 0\n",
    "        if times >= 5:\n",
    "            break\n",
    "        lastllik = llik\n",
    "    return ph1, phthtp, pvtht, llik\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面 EM 的循环过程中会监控 $ log{p(X \\mid \\theta)}$ 的值，如果连续五次改进的幅度都小于 0.003，则退出循环。\n",
    "\n",
    "下面是准备观察序列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 100\n",
    "N = 800\n",
    "vs = np.zeros((M, N), dtype=int)\n",
    "for m in range(M):\n",
    "    _, v = simulate(N)\n",
    "    vs[m, :] = np.array(v, dtype=int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后是针对观察序列多次运行 EM 算法，选择最好的一组参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- log likelihood: -170.0522129428408\n",
      "-- log likelihood: -173.4702767794389\n",
      "-- log likelihood: -170.05213799456536\n",
      "-- log likelihood: -173.46696749908853\n",
      "-- log likelihood: -173.40749679044217\n",
      "-- log likelihood: -170.05220115652392\n",
      "-- log likelihood: -170.052135100445\n",
      "-- log likelihood: -173.48174276900747\n",
      "-- log likelihood: -173.47633736243083\n",
      "-- log likelihood: -170.05224237070328\n",
      "ph1: [ 0.45943569  0.54056431]\n",
      "phthtp: [[ 0.99042401  0.00957599]\n",
      " [ 0.01548558  0.98451442]]\n",
      "pvtht: [[ 0.16195163  0.17027217  0.16431041  0.17508062  0.16408556  0.16429962]\n",
      " [ 0.10166069  0.10692512  0.10226344  0.09967972  0.10302182  0.48644921]]\n",
      "---- log likelihood: -170.052135100445\n"
     ]
    }
   ],
   "source": [
    "best = -np.inf\n",
    "best_pi = best_transp = best_emissp = None\n",
    "for _ in range(10):\n",
    "    ph1, phthtp, pvtht, llik = HMMem(vs, len(vs), 2, 6, 2000)\n",
    "    print(\"-- log likelihood: {}\".format(llik))\n",
    "    if llik > best:\n",
    "        best = llik\n",
    "        best_pi = ph1\n",
    "        best_transp = phthtp\n",
    "        best_emissp = pvtht\n",
    "        \n",
    "print(\"ph1: {}\".format(best_pi))\n",
    "print(\"phthtp: {}\".format(best_transp))\n",
    "print(\"pvtht: {}\".format(best_emissp))\n",
    "print(\"---- log likelihood: {}\".format(best))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到训练出来的参数与实际的参数是接近的。\n",
    "\n",
    "### 模型评估\n",
    "\n",
    "上面参数训练的过程就包含模型评估，也是提升模型与观察数据匹配度的过程。HMM 的模型评估由“前向”算法（forward）得出，即上面的 HMMforward 函数。\n",
    "\n",
    "模型评估本质上是求解 $p(Y) = \\sum_{X}p(Y, X)$，即对所有可能的 $X$ 组合计算 $p(Y, X)$ 的和。前向算法利用变量之间的条件无关性避免了大量的重复计算，从而提高了效率。具体的推导过程会跟 EM 算法的推导过程一起给出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小结\n",
    "\n",
    "这里主要借助掷色子的小例子讨论了与 HMM 相关的算法实现，显示了 HMM 的能力。以后会再介绍它在自然语言处理上的应用。\n",
    "\n",
    "HMM 是概率图模型的一个应用，所涉及的算法基本是概率图模型算法的特例。后续讨论概率图模型时会再来与 HMM 联系。\n",
    "\n",
    "上面省略的 EM 算法的推导过程会在下一篇中介绍。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
